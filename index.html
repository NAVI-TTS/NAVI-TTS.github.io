<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.66.0" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<link rel="stylesheet" href="../css/normalize.css">
<link rel="stylesheet" href="../css/skeleton.css">
<link rel="stylesheet" href="../css/custom.css">
<link rel="alternate" href="index.xml" type="application/rss+xml" title="Speech Research">
<link rel="shortcut icon" href="favicon.png" type="image/x-icon" />
<title>NAVI-TTS</title>
</head>
<body>

<div class="container">

	<header role="banner">
		
			
		
		
	</header>


	<main role="main">
		<article itemscope itemtype="https://schema.org/BlogPosting">
            <h1 class="entry-title" itemprop="headline">Development of Vietnamese Text-To-Speech for VLSP Challenge 2021</h1>
			
			<section itemprop="entry-text">
				<br>
<h2 id="authors">Authors</h2>
<ul>
<li>Le Minh Nguyen (HUST) <a href="mailto:nguyen.lm162998@sis.hust.edu.vn">nguyen.lm162998@sis.hust.edu.vn</a></li>
<li>Do Quoc An (HUST) <a href="mailto:an.dq194414@sis.hust.edu.vn">an.dq194414@sis.hust.edu.vn</a></li>
<li>Vu Quoc Viet (HUST) <a href="mailto:viet.vq194464@sis.hust.edu.vn">viet.vq194464@sis.hust.edu.vn</a></li>
<li>Vo Thuc Khanh Huyen (HUST) <a href="mailto:huyen.vtk190055@sis.hust.edu.vn">huyen.vtk190055@sis.hust.edu.vn</a></li>
</ul>
<p><small>Hanoi University of Science and Technology</small></p>
<h2 id="abstract">Abstract</h2>
<p>The Association for Vietnamese Language and Speech Processing (VLSP) has organized a series of workshop with the aim to bring together researchers and professionals working in NLP and to attempt a synthesis of research in Vietnamese language. One of the shared task held at the eighth workshop is TTS using dataset that only consists of spontaneous audio. This poses a challenge for current TTS models since they only perform well constructing reading-style speech (e.g, audiobook). Not only that, the quality of the audio provided by the dataset has a huge impact on the performance of the model. Specifically, samples with noisy background or with multiple voices speaking at the same time will deteriorate the performance of our model. In this paper, we describe our approach to tackle this problem: we first preprocess the training data then use it to train a <b>FastSpeech2</b> acoustic model with some replacements in external aligner model, finally we use <b>HiFiGAN</b> vocoder to construct the waveform. According to the official evaluation of VLSP 2021 competition in TTS task, our approach achieves <b>3.729</b> in-domain MOS, <b>3.557</b> out-of-domain MOS and <b>79.70%</b> SUS score.</p>
<h2 id="audio-samples">Audio Samples</h2>
<p>All of the audio samples use HiFiGAN as vocoder. For all audio samples, the background noise is reduced.</p>
<h3 id="comparison-with-other-models">Comparison with Other Models</h3>
<p><em>Were the leaders in this luckless change, though our own Baskerville, who was at work some years before them, went much on the same lines.</em></p>
<table><thead>
<tr>
<th style="text-align: center">GT</th>
<th style="text-align: center">Tacotron2</th>
<th style="text-align: center">FastSpeech2</th>
</tr></thead><tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/gt_recording_2/0000000004.mp3" autoplay/></audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio/gt_pwg_2/0000000004.mp3" autoplay/></audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/transtts_2/0000000004.mp3" autoplay/></audio></td>
</tr>
</tbody></table>
<h2 id="our-related-works">Our Related Works</h2>
<p><a href="/unsuper/">Almost Unsupervised Text to Speech and Automatic Speech Recognition</a><br>
<a href="/fastspeech/">FastSpeech: Fast, Robust and Controllable Text to Speech</a><br>
<a href="/seminas/">Semi-Supervised Neural Architecture Search</a><br>
<a href="/multispeech/">MultiSpeech: Multi-Speaker Text to Speech with Transformer</a><br>
<a href="/lrspeech/">LRSpeech: Extremely Low-Resource Speech Synthesis and Recognition</a><br>
<a href="/deepsinger/">DeepSinger: Singing Voice Synthesis with Data Mined From the Web</a><br>
<a href="/uwspeech/">UWSpeech: Speech to Speech Translation for Unwritten Languages</a><br>
<a href="/denoispeech/">Denoising Text to Speech with Frame-Level Noise Modeling</a><br></p>

			</section>
		</article>
	</main>
</div>

<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-139981676-1', 'auto');
	ga('send', 'pageview');
</script>

<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<script type="text/x-mathjax-config">
     MathJax.Hub.Config({
         HTML: ["input/TeX","output/HTML-CSS"],
         TeX: {
                Macros: {
                         bm: ["\\boldsymbol{#1}", 1],
                         argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                         argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
                extensions: ["AMSmath.js","AMSsymbols.js"],
                equationNumbers: { autoNumber: "AMS" } },
         extensions: ["tex2jax.js"],
         jax: ["input/TeX","output/HTML-CSS"],
         tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true },
         "HTML-CSS": { availableFonts: ["TeX"],
                       linebreaks: { automatic: true } }
     });
 </script>
 <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       tex2jax: {
         skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
       }
     });
 </script>

 <script type="text/javascript" async
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
 </script>
</body>
</html>